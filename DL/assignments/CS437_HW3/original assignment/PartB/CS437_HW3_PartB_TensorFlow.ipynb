{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of CS437_HW3_PartB_TensorFlow.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOEa1YQJNMIxs1HdNyBd2Am"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"oZYey2SB-Fkg"},"source":["# Assignment 3  - Part B  - TensorFlow\r\n","\r\n","\r\n","#### Roll Number:"]},{"cell_type":"markdown","metadata":{"id":"M-XLCrk6-ZdU"},"source":["You have a choice in Part B. You can either choose to do using TensorFlow or using Pytorch. Both are equally good and are widely used in industry.\r\n","\r\n","You are only required to do one of them. It's upto you to decide which one. However, you can also do both. In case you do both, you have to choose one as primary and and other one as secondary. Your primary one will be marked as normal and secondary one will marked for a 10% bonus.\r\n","\r\n","For example, if you do both and choose tensorflow as your primary attempt then you should primary in first heading of tensorflow notebook (Assignment 3  - Part B  - TensorFlow - Primary) and secondary (Assignment 3  - Part B  - Pytorch - Secondary) in pytorch notebook.\r\n","\r\n","In case, you only do one then you just need to submit that notebook."]},{"cell_type":"markdown","metadata":{"id":"onn5Uxj-K349"},"source":["### Task Explanation"]},{"cell_type":"markdown","metadata":{"id":"iQ3Xoi9P-UzM"},"source":["In this part we will implement, train and evaluate a neural network using tensorflow on wheat disease classification problem. \r\n","\r\n","Wheat rust is a devastating plant disease that affects many crops, reducing yields and affecting the livelihoods of farmers and decreasing food security across the continent. The disease is difficult to monitor at a large scale, making it difficult to control and eradicate.\r\n","\r\n","The objective of this challenge is to build a machine learning algorithm to correctly classify if a plant is healthy, has stem rust, or has leaf rust."]},{"cell_type":"markdown","metadata":{"id":"xV4Ov5bTMHTz"},"source":["### Let's Start"]},{"cell_type":"markdown","metadata":{"id":"qYaJpilbMVdw"},"source":["Make necessary imports here e.g. import cv2, import glob, etc"]},{"cell_type":"code","metadata":{"id":"KFtFdAki92gb"},"source":["import cv2\r\n","import glob\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","from tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Input, LeakyReLU, Flatten, Dropout\r\n","from tensorflow.keras.optimizers import Adam\r\n","from tensorflow.keras import Model\r\n","from sklearn.metrics import confusion_matrix\r\n","import pandas as pd\r\n","import seaborn as sns\r\n","# any other imports that you may require"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PIjSa95Wbihy"},"source":["### Hyperparameters"]},{"cell_type":"markdown","metadata":{"id":"o6UOIXtmXOWi"},"source":["You can play with these to improve accuracy on test data."]},{"cell_type":"code","metadata":{"id":"3HmKgWchbeth"},"source":["batch_size = 32\r\n","epochs = 30\r\n","learning_rate = 0.0001\r\n","input_shape = (256,256,3)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gZ3_V-64bx8O"},"source":["### Data"]},{"cell_type":"markdown","metadata":{"id":"R_MoIYfqOWrV"},"source":["Get Wheat Disease Data for training and testing"]},{"cell_type":"code","metadata":{"id":"X1zT4SRcOf06","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614025174766,"user_tz":-300,"elapsed":15553,"user":{"displayName":"Mubashar Fayyaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXl3J9i2D7CWyF7fg6gvx0AMvpR4lanBGTlWCq=s64","userId":"13227511005260906784"}},"outputId":"ddf29304-6925-4739-d9a4-f2eec979c959"},"source":["!git clone https://github.com/MMFa666/WheatDiseaseDataset.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'WheatDiseaseDataset'...\n","remote: Enumerating objects: 749, done.\u001b[K\n","remote: Total 749 (delta 0), reused 0 (delta 0), pack-reused 749\u001b[K\n","Receiving objects: 100% (749/749), 386.05 MiB | 43.96 MiB/s, done.\n","Checking out files: 100% (877/877), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x-IBjRssOstN"},"source":["Get paths for all the training images in the dataset and print the length of training_paths list. For this purpose you can use glob. You can have a look [here](https://www.geeksforgeeks.org/how-to-use-glob-function-to-find-files-recursively-in-python/) on how to use glob."]},{"cell_type":"code","metadata":{"id":"gACznLIwOnME"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vm3_jouMQlD8"},"source":["Do the same for testing data images."]},{"cell_type":"code","metadata":{"id":"H4t8VVDEQIHN"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PuMloSgvhuoq"},"source":["### Labels"]},{"cell_type":"code","metadata":{"id":"7gFoRUIdhN0w"},"source":["labels={}\r\n","labels['healthy_wheat'] = 0\r\n","labels['leaf_rust'] = 1\r\n","labels['stem_rust'] = 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rzE7J7vQXr42"},"source":["### Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"zaLNCsbAXkmD"},"source":["Preprocessing of data such as normalization, mean shift, make the learning task simple for network and could accelerate the training process. In this task, we will only do normaliztion.\r\n","\r\n","In images, pixel values range from 0 to 255. To shift the values between (0,1) range, divide input image by 255.\r\n"]},{"cell_type":"code","metadata":{"id":"94HiFqveQwGY"},"source":["def preprocessing_norm(images):\r\n","    pass"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S48J0KtpXm7w"},"source":["### Batch Generator"]},{"cell_type":"markdown","metadata":{"id":"LuyUCA9BYXER"},"source":["Previously, when training our models, we were loading the complete data in memory to fit our model. However, in practice we're working with very large datasets which cannot be loaded all at once in memory. As a solution, we use \"Data Generators\" which are essentially python generators that load batches of data from disk into memory and pass into our models. In order to achieve this, we only store filepaths that point to training/test samples in our dataset in memory. A data generator yields a tuple of (Xs,Ys) whenever the generator is used via the next() function. \r\n","\r\n","For examples of batch_generators, you can have a look [here](https://www.geeksforgeeks.org/generators-in-python/) or [here](https://www.programcreek.com/python/?CodeExample=generate+batches). Essentially you have to the following:\r\n","- Shuffle the paths to get a uniform distribution in all batches.\r\n","- Divide paths into batches.\r\n","- Read image from the path. (Remeber cv2 reads image in BGR format.)\r\n","- Resize each image to input_shape.\r\n","- Extract label of the image from the image path using folder name. (Hint: You can do this by splitting the path.)\r\n","- One-hot encode the labels.\r\n","- Yield images and labels in tuple.\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"ETFQgnFOYTLt"},"source":["# Batch generator function here.\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_AsJysziNYF"},"source":["Initialize train data generator"]},{"cell_type":"code","metadata":{"id":"WawdX9uXg9A9"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qYyw9GnXjCWL"},"source":["### Training"]},{"cell_type":"markdown","metadata":{"id":"MWlGg_lgigzp"},"source":["Build model here. Use Functional API of tensorflow to this. You can have a look [here](https://www.tensorflow.org/guide/keras/functional) to understand how this works.\r\n","\r\n","Model Architecture:\r\n","- See model.png for model architecture\r\n","- Filter size in each convolution layer is 3 except first convolution where it is 5.\r\n","- The stride in each convolution layer is 2.\r\n","- There is no padding in convolution layer.\r\n","- Dropout = 0.2 on each dropout layer.\r\n","- The last layer has softmax activation.\r\n","- The model should have 491,443 total parameters.\r\n"]},{"cell_type":"code","metadata":{"id":"BqtPQJq3ifkT"},"source":["# Code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICCO7PkclXxx"},"source":["#print model summary here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rdMNyisQolHQ"},"source":["Compile your model here. (Hint: use model.compile() ) See [this](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) documentation or the above link to know how to do this. \r\n","\r\n","Use the following specifications:\r\n","- optimizer: Adam\r\n","- metrics: accuracy\r\n","- loss: categorical_crossentropy"]},{"cell_type":"code","metadata":{"id":"4P38jPGImOgN"},"source":["# Code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pbdoekcgqcG8"},"source":["Fit your model here. (Hint: use model.fit() ) See [this](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) documentation or the above link again to know how to do this."]},{"cell_type":"code","metadata":{"id":"iDJ4fwcxqQzd"},"source":["# Code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kyJpvWw4Qqj5"},"source":["Plot the loss and accuracy graphs of training. Use hist.history['loss'] and hist.history['accuracy'] where hist is returned by model.fit()"]},{"cell_type":"code","metadata":{"id":"fWjSBUpaREsx"},"source":["# Loss Plot\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J5SwbAawRbiF"},"source":["# Accuracy Plot\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E93C9atGR5Ln"},"source":["### Evaluation"]},{"cell_type":"markdown","metadata":{"id":"yA1THUmuR7Ca"},"source":["Now, we will evaluate our model on the test data."]},{"cell_type":"markdown","metadata":{"id":"P-1_GjKfSA0B"},"source":["First, let's read the test data using test_paths. Similar to what we did in batch_generator."]},{"cell_type":"code","metadata":{"id":"wJU9SfXsSHg4"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iDm1xMHQSh7w"},"source":["Now, make predictions on test data. (Hint: use model.predict() )."]},{"cell_type":"code","metadata":{"id":"nW6lX6yUSc0T"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f6H6NU4wTKzI"},"source":["Extract class label from predictions. (Hint: you can use np.argmax() )."]},{"cell_type":"code","metadata":{"id":"fys8SnxKTGAN"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MKuaxM4wT164"},"source":["Calculate and print accuracy."]},{"cell_type":"code","metadata":{"id":"bgRi2n7KT0oU"},"source":["# code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JXsP39xDUWez"},"source":["Calculate and print Confusion Matrix. Have a look [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) for this."]},{"cell_type":"code","metadata":{"id":"CX2DU3CAUVzz"},"source":["# code here\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tcVttT8T6YxA"},"source":["def plot_confusion_matrix(conf_mat):\r\n","    classes = list(labels.keys())\r\n","    df_cm = pd.DataFrame(conf_mat,classes,classes)\r\n","    plt.figure(figsize=(10,7))\r\n","    sns.set(font_scale=1.4)\r\n","    sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\r\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9w7a2UdCWJ3Q"},"source":["Use the above function to plot confusion matrix here."]},{"cell_type":"code","metadata":{"id":"U5O9Uxo9VUHc"},"source":["# code below\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m29EU7mZVrD3"},"source":["### Questions\r\n"]},{"cell_type":"markdown","metadata":{"id":"SxetUutBW9Px"},"source":["\r\n","What is overfitting? How are we trying to prevent overfitting here?\r\n","\r\n","Answer:\r\n"]},{"cell_type":"markdown","metadata":{"id":"2QeB-aefW64T"},"source":["What is class imbalance? How does it effect training? Does this training set have class imbalance? If yes, then show it (using numbers).\r\n","\r\n","Answer:"]},{"cell_type":"code","metadata":{"id":"qxrE4fN-VXNn"},"source":[""],"execution_count":null,"outputs":[]}]}