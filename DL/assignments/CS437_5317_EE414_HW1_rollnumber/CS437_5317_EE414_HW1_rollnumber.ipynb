{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "notify_time": "5",
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "hw1_rollnumber.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8t4yditbX_Q"
      },
      "source": [
        "**Colab Notebook Sharing Link(edit access)**: ***Enter Here***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpn9k3BV1X2s"
      },
      "source": [
        "# CS 437 - Deep Learning - PA1:Neural Network Class\n",
        "\n",
        "*__Submission Instructions:__*\n",
        "- Rename this notebook to `hw1_rollnumber.ipynb` before submission on LMS.\n",
        "- All code must be written in this notebook (you do not need to submit any other files).\n",
        "- The output of all cells must be present in the version of the notebook you submit. You will be penalized if the output is absent.\n",
        "- The university honor code should be maintained. Any violation, if found, will result in disciplinary action. \n",
        "- You have to download assignment from LMS and do all your workings on colab. Don't download the files again and again.\n",
        "- You can share the notebook link of your colab noteboob in the begining of the notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-30T14:39:17.671980Z",
          "start_time": "2019-01-30T14:38:40.137027Z"
        },
        "id": "UPL8Ut1u1X2-"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn')\n",
        "from IPython.display import Image\n",
        "import pydot\n",
        "from tqdm import tqdm_notebook\n",
        "import seaborn as sns\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdFtEQ5O1X2_"
      },
      "source": [
        "**Please write your roll number in the next cell**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-30T14:36:37.383767Z",
          "start_time": "2019-01-30T14:36:37.333537Z"
        },
        "id": "xU_yqbc31X2_"
      },
      "source": [
        "rollnumber = 22100000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9cjup_91X2_"
      },
      "source": [
        "In this assignment you will be creating 4 versions of the `NeuralNetwork` class. You will start with a simple 2 layer feed forward network and progressively modify the class by adding features to make it more generic. At the end you will have implemented a version which can create networks of arbitrary shape and depth, and which will work for both regression and classification tasks. \n",
        "\n",
        "Often in pratical situations, raw machine learning architecture and code is hidden behind libraries and simplfied toolkits. The purpose of this assignment is to lift that curtain and get you hands-on exprience working with the mathematical fundamentals of neural network architectures. After this, you'll know exactly how a network leverages 'gradient descent' to find optimal solutions and how forward and backward passes are implemented mathematically and in code.\n",
        "\n",
        "\n",
        "### Primary Task\n",
        "Skeleton code is provided to get you started; the main methods you need to implement correspond to the 3 steps of the training process, namely:\n",
        "1. Initialize variables and initialize weights\n",
        "2. Forward pass\n",
        "3. Backward pass AKA Backpropogation\n",
        "4. Weight Update AKA Gradient Descent\n",
        "\n",
        "__Look for comments in the code to see where you are supposed to write code.__ Essentially, you will be working on 5 functions. \n",
        "You should use the lecture [slides]() as reference for the equations. \n",
        "\n",
        "A `fit` function is what combines the previous three functions and overall trains the network to __fit__ to the provided training examples. In all the following tasks, the provided `fit` methods require the three steps of the training process to be correctly working. The function has been setup in a way that it expects the above 3 methods to take particular inputs and return particular outputs. __You are supposed to work within this restriction.__ Modification of the provided code without prior discussion with the TAs will result in a __grade deduction__. \n",
        "\n",
        "\n",
        "\n",
        "To see how well your model is doing, you need to look at the dummy tasks (at the end) and make sure your model loss is going down during training. A dummy regression task of adding two numbers (sum less than 1) has been provided as well. Similarly, a dummy classification task (XOR logic gate) is also present. You can look at the shapes of the inputs and outputs matrices as well as the training trend (once you implement a full task) by using your own class (make sure you are using the correct arguments to the `__init__` method). \n",
        "\n",
        "You can find a demonstration of the neural network working on a synthetic dataset for both regression and classification at the end of the notebook. After you implement your class fully, you can play with the parameters and see the visualization change, we highly recommend that you try this. This part of the notebook will not be graded in any way, but it might give you a better insight/intuition into how the model makes decisions, and how important parameters are in terms of the usefullness of neural networks. You will explore the parameter space more thoroughly in the next assignment :P\n",
        "\n",
        "### Side note\n",
        "*The `plot_model` method will only work if you have the `pydot` python package installed along with [Graphviz](https://graphviz.gitlab.io/download/)). If you do not wish to use this then simply comment out the import for `pydot`.*\n",
        "\n",
        "### Need Help?\n",
        "If you need help, refer to your textbook (provided on LMS) which has examples and explanations for all the processes you'll have to implement, as well as rich details on functions such as `sigmoid` and `softmax`. Going over the book once before getting started is a good idea, you can also refer to the class slides and supplemental material provided with the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "Jv0mUoiB1X3B"
      },
      "source": [
        "## Task 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "QOxoQ-_B1X3B"
      },
      "source": [
        "In this task you will implement the simplest version of a feed forward neural network - a 2 layer network. \n",
        "\n",
        "Your code will only be partially vectorized, this means that you will be passing a single data point through the network at a time. In simple terms, the running time of your `fit` method will be $O(e*n)$ where $e$ is the number of epochs and $n$ is the number of data points (assuming all functions/methods called in `fit` take constant time). \n",
        "\n",
        "This version of the network will be using the `softmax` activation function for the output layer and `sigmoid` for the hidden layer, *ie.* a classification model which learns to output the joint probability mass function of the classes in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y-6i2TL1X3C"
      },
      "source": [
        "def plot_confusion_matrix(conf_mat):\n",
        "    classes = ['T-shirt/top','Trouser/pants','Pullover shirt','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n",
        "    df_cm = pd.DataFrame(conf_mat,classes,classes)\n",
        "    plt.figure(figsize=(15,9))\n",
        "    sns.set(font_scale=1.4)\n",
        "    sns.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})\n",
        "    plt.show()\n",
        "\n",
        "class_labels = ['T-shirt/top','Trouser/pants','Pullover shirt','Dress','Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:25:17.044301Z",
          "start_time": "2019-01-27T01:25:16.984346Z"
        },
        "hidden": true,
        "id": "iP5ZI2Rs1X3C"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_pred, y_true):\n",
        "        # implement cross_entropy_loss function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        # implement accuracy function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        # implement softmax function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        #TO DO\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    def __init__(self, input_size, hidden_nodes, output_size):\n",
        "        '''Creates a Feed-Forward Neural Network.\n",
        "        The parameters represent the number of nodes in each layer (total 3). \n",
        "        Look at the inputs to the function'''\n",
        "        self.num_layers = None  # includes input layer\n",
        "        self.input_shape = None\n",
        "        self.hidden_shape = None\n",
        "        self.output_shape = None\n",
        "        self.weights_ = self.biases_ = []\n",
        "        self.__init_weights()\n",
        "    def __init_weights(self):\n",
        "        '''Initializes all weights based on standard normal distribution and all biases to 0.'''\n",
        "        W_h = np.random.normal(size=(None, None))\n",
        "        b_h = np.zeros(shape=(None,))\n",
        "        \n",
        "        W_o = np.random.normal(size=(None, None))\n",
        "        b_o = np.zeros(shape=(None,))\n",
        "        \n",
        "        self.weights_ = None\n",
        "        self.biases_  = None\n",
        "        \n",
        "    \n",
        "    def forward_pass(self, input_data):\n",
        "        '''Executes the feed forward algorithm.\n",
        "        \"input_data\" is the input to the network in row-major form\n",
        "        Returns \"activations\", which is a list of all layer outputs (excluding input layer of course)'''\n",
        "        \n",
        "        return activations\n",
        "    \n",
        "    def backward_pass(self, targets, layer_activations):\n",
        "        '''Executes the backpropogation algorithm.\n",
        "        \"targets\" is the ground truth/labels\n",
        "        \"layer_activations\" are the return value of the forward pass step\n",
        "        Returns \"deltas\", which is a list containing weight update values for all layers (excluding the input layer of course)'''        \n",
        "        return deltas\n",
        "\n",
        "    def weight_update(self, deltas, layer_inputs, lr):\n",
        "        '''Executes the gradient descent algorithm.\n",
        "        \"deltas\" is return value of the backward pass step\n",
        "        \"layer_inputs\" is a list containing the inputs for all layers (including the input layer)\n",
        "        \"lr\" is the learning rate'''\n",
        "        \n",
        "    \n",
        "    def fit(self, Xs, Ys, epochs, lr=1e-3):\n",
        "            history = []\n",
        "            # for \n",
        "            for epoch in tqdm_notebook(range(epochs)):\n",
        "                num_samples = Xs.shape[0]\n",
        "                for i in range(num_samples):\n",
        "                    sample_input = Xs[i,:].reshape((1,self.input_shape))\n",
        "                    sample_target = Ys[i,:].reshape((1,self.output_shape))\n",
        "\n",
        "                    activations = None # Call forward_pass function \n",
        "                    deltas = None # Call backward_pass function \n",
        "                    layer_inputs = [sample_input] + activations[:-1]\n",
        "                    # Call weight_update function \n",
        "                    None\n",
        "                preds = None # Call predict function \n",
        "                current_loss = self.cross_entropy_loss(preds, Ys)\n",
        "                if  epoch==epochs-1:\n",
        "                  confusion_mat=confusion_matrix(Ys.argmax(axis=1), preds.argmax(axis=1))  \n",
        "                  plot_confusion_matrix(confusion_mat)\n",
        "                  report = classification_report(Ys, np_utils.to_categorical(preds.argmax(axis=1)), target_names=class_labels)\n",
        "                  print(report)\n",
        "                history.append(current_loss)\n",
        "            return history\n",
        "    \n",
        "    def predict(self, Xs):\n",
        "        '''Returns the model predictions (output of the last layer) for the given \"Xs\".'''\n",
        "        predictions = []\n",
        "        num_samples = Xs.shape[0]\n",
        "        for i in range(num_samples):\n",
        "            sample = Xs[i,:].reshape((1,self.input_shape))\n",
        "            sample_prediction = self.forward_pass(sample)[-1]\n",
        "            predictions.append(sample_prediction.reshape((self.output_shape,)))\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def evaluate(self, Xs, Ys):\n",
        "        '''Returns appropriate metrics for the task, calculated on the dataset passed to this method.'''\n",
        "        pred = self.predict(Xs)\n",
        "        return self.cross_entropy_loss(pred, Ys), self.accuracy(pred.argmax(axis=1), Ys.argmax(axis=1))\n",
        "    \n",
        "    def plot_model(self, filename):\n",
        "        '''Provide the \"filename\" as a string including file extension. Creates an image showing the model as a graph.'''\n",
        "        graph = pydot.Dot(graph_type='digraph')\n",
        "        graph.set_rankdir('LR')\n",
        "        graph.set_node_defaults(shape='circle', fontsize=0)\n",
        "        nodes_per_layer = [self.input_shape, self.hidden_shape, self.output_shape]\n",
        "        for i in range(self.num_layers-1):\n",
        "            for n1 in range(nodes_per_layer[i]):\n",
        "                for n2 in range(nodes_per_layer[i+1]):\n",
        "                    edge = pydot.Edge(f'l{i}n{n1}', f'l{i+1}n{n2}')\n",
        "                    graph.add_edge(edge)\n",
        "        graph.write_png(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd_bEGMF1oa2"
      },
      "source": [
        "\n",
        "classes = 10\n",
        "#Download Fashion MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "#Split the fashion MNIST dataset into train, validation and test sets (Done for you)\n",
        "#Convert y_train,y_val and y_test to categorical binary values \n",
        "#TO DO\n",
        "\n",
        "\n",
        "\n",
        "#See function \"np_utils.to_categorical()\"\n",
        "#Reshape images of X_train and X_test to 1d array\n",
        "\n",
        "#TO DO\n",
        "\n",
        "#See function of numpy reshape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRtc2Dzc2D_H"
      },
      "source": [
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "# Define the input size and output size of  Fashion MNIST dataset\n",
        "\n",
        "nn = NeuralNetwork(input_size=None, hidden_nodes=80, output_size=None)\n",
        "# You can tweak the learning rate and epochs to know how things work\n",
        "history = nn.fit(X_train, y_train, epochs=10, lr=0.01)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='Cross-entropy', title='Training Plot {}'.format(rollnumber));\n",
        "# end time\n",
        "end = time.time()\n",
        "print(\"Runtime of the algorithm is \",round((end - start),3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "YxD_ligU1X3K"
      },
      "source": [
        "## Task 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Ne2uSY9k1X3K"
      },
      "source": [
        "Now you will modify the class to allow the option to learn a regression model. You need to change some methods to account for the `mode` of the network. You can copy your code from task 1 as a starting point if you want.\n",
        "\n",
        "If the `mode` is classification, you will use your code from Task1. In case of the `mode` being regression you will apply the `sigmoid` activation function to both layers and compute the deltas for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:30:16.547173Z",
          "start_time": "2019-01-27T01:30:16.441918Z"
        },
        "hidden": true,
        "id": "zjySHMrK1X3K"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    @staticmethod\n",
        "    def mean_squared_error(y_pred, y_true):\n",
        "        # implement mean_squared_error function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_pred, y_true):\n",
        "        # implement cross_entropy_loss function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        # implement accuracy function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        # implement softmax function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        #TO DO\n",
        "        \n",
        "        return None\n",
        "    \n",
        "    \n",
        "    def __init__(self, input_size, hidden_nodes, output_size, mode):\n",
        "        '''Creates a Feed-Forward Neural Network.\n",
        "        \"mode\" can be one of 'regression' or 'classification' and controls the output activation as well as training metric\n",
        "        The rest of the parameters represent the number of nodes in each layer (total 3).'''\n",
        "        if mode not in ['classification','regression']:\n",
        "            raise ValueError('Only \"classification\" and \"regression\" modes are supported.')\n",
        "        \n",
        "        self.num_layers = None # includes input layer\n",
        "        self.input_shape = None\n",
        "        self.hidden_shape = None\n",
        "        self.output_shape = None\n",
        "        self.mode = None\n",
        "        \n",
        "        \n",
        "        self.weights_ = self.biases_ = []\n",
        "        self.__init_weights()\n",
        "    \n",
        "    def __init_weights(self):\n",
        "        '''Initializes all weights based on standard normal distribution and all biases to 0.'''\n",
        "        W_h = np.random.normal(size=(None, None))\n",
        "        b_h = np.zeros(shape=(None,))\n",
        "        \n",
        "        W_o = np.random.normal(size=(None, None))\n",
        "        b_o = np.zeros(shape=(None,))\n",
        "        \n",
        "        self.weights_ = None\n",
        "        self.biases_  = None\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    def forward_pass(self, input_data):\n",
        "        '''Executes the feed forward algorithm.\n",
        "        \"input_data\" is the input to the network in row-major form\n",
        "        Returns \"activations\", which is a list of all layer outputs (excluding input layer of course)'''\n",
        "        \n",
        "            \n",
        "        return activations\n",
        "    \n",
        "    def backward_pass(self, targets, layer_activations):\n",
        "        '''Executes the backpropogation algorithm.\n",
        "        \"targets\" is the ground truth/labels\n",
        "        \"layer_activations\" are the return value of the forward pass step\n",
        "        Returns \"deltas\", which is a list containing weight update values for all layers (excluding the input layer of course)'''\n",
        "        \n",
        "        \n",
        "        return deltas\n",
        "    \n",
        "    def weight_update(self, deltas, layer_inputs, lr):\n",
        "        '''Executes the gradient descent algorithm.\n",
        "        \"deltas\" is return value of the backward pass step\n",
        "        \"layer_inputs\" is a list containing the inputs for all layers (including the input layer)\n",
        "        \"lr\" is the learning rate'''\n",
        "        \n",
        "        \n",
        "    \n",
        "    \n",
        "    def fit(self, Xs, Ys, epochs, lr=1e-3):\n",
        "        '''Trains the model on the given dataset for \"epoch\" number of itterations with step size=\"lr\". \n",
        "        Returns list containing loss for each epoch.'''\n",
        "        history = []\n",
        "        for epoch in tqdm_notebook(range(epochs)):\n",
        "            num_samples = Xs.shape[0]\n",
        "            for i in range(num_samples):\n",
        "                if(i+2 <= num_samples):\n",
        "                    sample_input = Xs[i:i+2,:].reshape((1,self.input_shape))\n",
        "                    sample_target = Ys[i,:].reshape((1,self.output_shape))\n",
        "                \n",
        "                    activations = None # Call forward_pass function  \n",
        "                    deltas = None # Call backward_pass function\n",
        "\n",
        "                    layer_inputs = [sample_input] + activations[:-1]\n",
        "                    # Call weight_update function\n",
        "                    None\n",
        "\n",
        "            preds = None  # Call predict function \n",
        "            if self.mode == 'regression':\n",
        "                current_loss = self.mean_squared_error(preds, Ys[:-1])\n",
        "            elif self.mode == 'classification':\n",
        "                current_loss = self.cross_entropy_loss(preds, Ys[:-1])\n",
        "            history.append(current_loss)\n",
        "        return history\n",
        "    \n",
        "    def predict(self, Xs):\n",
        "        '''Returns the model predictions (output of the last layer) for the given \"Xs\".'''\n",
        "        predictions = []\n",
        "        num_samples = Xs.shape[0]\n",
        "        for i in range(num_samples):\n",
        "            if(i+2 <= num_samples):\n",
        "                sample = Xs[i:i+2,:].reshape((1,self.input_shape))\n",
        "                sample_prediction = self.forward_pass(sample)[-1]\n",
        "                predictions.append(sample_prediction.reshape((self.output_shape,)))\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def evaluate(self, Xs, Ys):\n",
        "        '''Returns appropriate metrics for the task, calculated on the dataset passed to this method.'''\n",
        "        pred = self.predict(Xs)\n",
        "        if self.mode == 'regression':\n",
        "            return self.mean_squared_error(pred, Ys)\n",
        "        elif self.mode == 'classification':\n",
        "            return self.cross_entropy_loss(pred, Ys), self.accuracy(pred.argmax(axis=1), Ys.argmax(axis=1))\n",
        "    \n",
        "    def plot_model(self, filename):\n",
        "        '''Provide the \"filename\" as a string including file extension. Creates an image showing the model as a graph.'''\n",
        "        graph = pydot.Dot(graph_type='digraph')\n",
        "        graph.set_rankdir('LR')\n",
        "        graph.set_node_defaults(shape='circle', fontsize=0)\n",
        "        nodes_per_layer = [self.input_shape, self.hidden_shape, self.output_shape]\n",
        "        for i in range(self.num_layers-1):\n",
        "            for n1 in range(nodes_per_layer[i]):\n",
        "                for n2 in range(nodes_per_layer[i+1]):\n",
        "                    edge = pydot.Edge(f'l{i}n{n1}', f'l{i+1}n{n2}')\n",
        "                    graph.add_edge(edge)\n",
        "        graph.write_png(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbSFGpT1aATA"
      },
      "source": [
        "nn = NeuralNetwork(input_size=2, hidden_nodes=5, output_size=1, mode='regression')\n",
        "nn.plot_model('graph.png')\n",
        "Image('graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoUiximFaDCd"
      },
      "source": [
        "data_x, _ = make_moons(200, noise=0.18)\n",
        "plt.scatter(data_x[:,0], data_x[:,1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7qpoQt1X3L"
      },
      "source": [
        "reg = LinearRegression()\n",
        "reg = reg.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "\n",
        "d = np.arange(-1.5, 2.5, 0.1).reshape((40,1))\n",
        "preds = reg.predict(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehZwKJPLaEQu"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Linear Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvFaMw5ETOEI"
      },
      "source": [
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "\n",
        "nn = NeuralNetwork(input_size=2, hidden_nodes=6, output_size=1, mode='regression')\n",
        "history = nn.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)), epochs=200, lr=1e-4)\n",
        "preds = nn.predict(d)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='MSE', title='Training Plot {}'.format(rollnumber));\n",
        "# end time\n",
        "end = time.time()\n",
        "print(\"Runtime of the algorithm is \",round((end - start),3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "vjLb49531X3N"
      },
      "source": [
        "## Task 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "Z1eCdRmk1X3N"
      },
      "source": [
        "Again, if it helps copy only your code from Task2 as a starting point in the next cell. Now you will modify the class to allow an arbitrarily shaped network. \n",
        "\n",
        "*Hint: The output/last layer is special in terms of the delta calculation. All the hidden layers have the same calculation (chain rule)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:30:16.547173Z",
          "start_time": "2019-01-27T01:30:16.441918Z"
        },
        "hidden": true,
        "id": "rpVDYPBu1X3N"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    @staticmethod\n",
        "    def mean_squared_error(y_pred, y_true):\n",
        "        # implement mean_squared_error function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_pred, y_true):\n",
        "        # implement cross_entropy_loss function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        # implement accuracy function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        # implement softmax function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        # implement sigmoid function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "        \n",
        "    \n",
        "    def __init__(self, nodes_per_layer, mode):\n",
        "        '''Creates a Feed-Forward Neural Network.\n",
        "        \"nodes_per_layer\" is a list containing number of nodes in each layer (including input layer)\n",
        "        \"mode\" can be one of 'regression' or 'classification' and controls the output activation as well as training metric'''\n",
        "        if len(nodes_per_layer) < 2:\n",
        "            raise ValueError('Network must have atleast 2 layers (input and output).')\n",
        "        if not (np.array(nodes_per_layer) > 0).all():\n",
        "            raise ValueError('Number of nodes in all layers must be positive.')\n",
        "        if mode not in ['classification','regression']:\n",
        "            raise ValueError('Only \"classification\" and \"regression\" modes are supported.')\n",
        "        \n",
        "        self.num_layers = None # includes input layer\n",
        "        self.nodes_per_layer = None\n",
        "        self.input_shape = None\n",
        "        self.output_shape = None\n",
        "        self.mode = None\n",
        "        \n",
        "        \n",
        "        self.__init_weights(nodes_per_layer)\n",
        "    \n",
        "    def __init_weights(self, nodes_per_layer):\n",
        "        '''Initializes all weights based on standard normal distribution and all biases to 0.'''\n",
        "        self.weights_ = []\n",
        "        self.biases_ = []\n",
        "        for i,_ in enumerate(nodes_per_layer):\n",
        "            if i == 0:\n",
        "                # skip input layer, it does not have weights/bias\n",
        "                continue\n",
        "            \n",
        "            weight_matrix = np.random.normal(size=(None, None))\n",
        "            self.weights_.append(None)\n",
        "            bias_vector = np.zeros(shape=(None,))\n",
        "            self.biases_.append(None)\n",
        "    \n",
        "\n",
        "    def forward_pass(self, input_data):\n",
        "        '''Executes the feed forward algorithm.\n",
        "        \"input_data\" is the input to the network in row-major form\n",
        "        Returns \"activations\", which is a list of all layer outputs (excluding input layer of course)'''\n",
        "                \n",
        "        return activations\n",
        "    \n",
        "    def backward_pass(self, targets, layer_activations):\n",
        "        '''Executes the backpropogation algorithm.\n",
        "        \"targets\" is the ground truth/labels\n",
        "        \"layer_activations\" are the return value of the forward pass step\n",
        "        Returns \"deltas\", which is a list containing weight update values for all layers (excluding the input layer of course)'''\n",
        "\n",
        "        return deltas\n",
        "    \n",
        "    def weight_update(self, deltas, layer_inputs, lr):\n",
        "        '''Executes the gradient descent algorithm.\n",
        "        \"deltas\" is return value of the backward pass step\n",
        "        \"layer_inputs\" is a list containing the inputs for all layers (including the input layer)\n",
        "        \"lr\" is the learning rate'''\n",
        "    \n",
        "    def fit(self, Xs, Ys, epochs, lr=1e-3):\n",
        "        '''Trains the model on the given dataset for \"epoch\" number of itterations with step size=\"lr\". \n",
        "        Returns list containing loss for each epoch.'''\n",
        "        history = []\n",
        "        print(Xs.shape)\n",
        "        print(Ys.shape)\n",
        "        for epoch in tqdm_notebook(range(epochs)):\n",
        "            num_samples = Xs.shape[0]\n",
        "            for i in range(num_samples):\n",
        "                sample_input = Xs[i,:].reshape((1,self.input_shape))\n",
        "                sample_target = Ys[i,:].reshape((1,self.output_shape))\n",
        "                \n",
        "                activations =  None # Call forward_pass function  \n",
        "                deltas =  None # Call backward_pass function  \n",
        "\n",
        "                layer_inputs = [sample_input] + activations[:-1]\n",
        "                None # Call weight_update function  \n",
        "            preds = None # Call predict function \n",
        "            if self.mode == 'regression':\n",
        "                current_loss = self.mean_squared_error(preds, Ys)\n",
        "            elif self.mode == 'classification':\n",
        "                current_loss = self.cross_entropy_loss(preds, Ys)\n",
        "            history.append(current_loss)\n",
        "        return history\n",
        "    \n",
        "    def predict(self, Xs):\n",
        "        '''Returns the model predictions (output of the last layer) for the given \"Xs\".'''\n",
        "        predictions = []\n",
        "        num_samples = Xs.shape[0]\n",
        "        for i in range(num_samples):\n",
        "            sample = Xs[i,:].reshape((1,self.input_shape))\n",
        "            sample_prediction = self.forward_pass(sample)[-1]\n",
        "            predictions.append(sample_prediction.reshape((self.output_shape,)))\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def evaluate(self, Xs, Ys):\n",
        "        '''Returns appropriate metrics for the task, calculated on the dataset passed to this method.'''\n",
        "        pred = self.predict(Xs)\n",
        "        if self.mode == 'regression':\n",
        "            return self.mean_squared_error(pred, Ys)\n",
        "        elif self.mode == 'classification':\n",
        "            return self.cross_entropy_loss(pred, Ys), self.accuracy(pred.argmax(axis=1), Ys.argmax(axis=1))\n",
        "    \n",
        "    def plot_model(self, filename):\n",
        "        '''Provide the \"filename\" as a string including file extension. Creates an image showing the model as a graph.'''\n",
        "        graph = pydot.Dot(graph_type='digraph')\n",
        "        graph.set_rankdir('LR')\n",
        "        graph.set_node_defaults(shape='circle', fontsize=0)\n",
        "        for i in range(self.num_layers-1):\n",
        "            for n1 in range(self.nodes_per_layer[i]):\n",
        "                for n2 in range(self.nodes_per_layer[i+1]):\n",
        "                    edge = pydot.Edge(f'l{i}n{n1}', f'l{i+1}n{n2}')\n",
        "                    graph.add_edge(edge)\n",
        "        graph.write_png(filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmSEEOAgaIAF"
      },
      "source": [
        "nn = NeuralNetwork([2,5,2], 'classification')\n",
        "nn.plot_model('graph.png')\n",
        "Image('graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZPU52GyaLTC"
      },
      "source": [
        "\n",
        "\n",
        "dataset = pd.DataFrame({\n",
        "    'var1':   [0, 0, 1, 1],\n",
        "    'var2':   [0, 1, 0, 1],\n",
        "    'output': [0, 1, 1, 0],\n",
        "})\n",
        "dataset = pd.get_dummies(dataset, columns=['output'])\n",
        "dataset['output'] = pd.Series([0, 1, 1, 0])\n",
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "nn = NeuralNetwork([2,5,2], 'classification')\n",
        "history = nn.fit(dataset[['var1','var2']].values, dataset[['output_0','output_1']].values, epochs=3000, lr=0.01)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='Cross-entropy', title='Training Plot {}'.format(rollnumber));\n",
        "# end time\n",
        "end = time.time()\n",
        "print(\"Runtime of the algorithm is \",round((end - start),3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHUC1Wb1X3O"
      },
      "source": [
        "## Task 4 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EacCocHS1X3O"
      },
      "source": [
        "You should copy your code from task3 as a starting point. You have to modify the forward and backward passes to use a different activation function; the Rectified Linear Unit (ReLu). You can look at the research papers or articles online for derivatives and other explanations. \n",
        "\n",
        "In this task you need to implement the activation function and its derivative yourself. You can use a separate function for derivative of activation function or include the expression in the derivative calculation. For classification, we will use softmax for output layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIoc-S811X3O"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    @staticmethod\n",
        "    def mean_squared_error(y_pred, y_true):\n",
        "        # implement mean_squared_error function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_pred, y_true):\n",
        "        # implement cross_entropy_loss function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        # implement accuracy function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "\n",
        "    @staticmethod\n",
        "    def relu(x):\n",
        "        # implement relu function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def relu_der(x):\n",
        "        # implement relu_der function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "\n",
        "        \n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        # implement softmax function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        # implement sigmoid function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    def __init__(self, nodes_per_layer, mode):\n",
        "        '''Creates a Feed-Forward Neural Network.\n",
        "        \"nodes_per_layer\" is a list containing number of nodes in each layer (including input layer)\n",
        "        \"mode\" can be one of 'regression' or 'classification' and controls the output activation as well as training metric'''\n",
        "        if len(nodes_per_layer) < 2:\n",
        "            raise ValueError('Network must have atleast 2 layers (input and output).')\n",
        "        if not (np.array(nodes_per_layer) > 0).all():\n",
        "            raise ValueError('Number of nodes in all layers must be positive.')\n",
        "        if mode not in ['classification','regression']:\n",
        "            raise ValueError('Only \"classification\" and \"regression\" modes are supported.')\n",
        "        \n",
        "        self.num_layers = None # includes input layer\n",
        "        self.nodes_per_layer = None\n",
        "        self.input_shape = None\n",
        "        self.output_shape = None\n",
        "        self.mode = None\n",
        "        \n",
        "        \n",
        "        self.__init_weights(nodes_per_layer)\n",
        "    \n",
        "    def __init_weights(self, nodes_per_layer):\n",
        "        '''Initializes all weights based on standard normal distribution and all biases to 0.'''\n",
        "        self.weights_ = []\n",
        "        self.biases_ = []\n",
        "        for i,_ in enumerate(nodes_per_layer):\n",
        "            if i == 0:\n",
        "                # skip input layer, it does not have weights/bias\n",
        "                continue\n",
        "            \n",
        "            weight_matrix = np.random.normal(size=(None, None))\n",
        "            self.weights_.append(None)\n",
        "            bias_vector = np.zeros(shape=(None,))\n",
        "            self.biases_.append(None)\n",
        "\n",
        "    \n",
        "    def forward_pass(self, input_data):\n",
        "        '''Executes the feed forward algorithm.\n",
        "        \"input_data\" is the input to the network in row-major form\n",
        "        Returns \"activations\", which is a list of all layer outputs (excluding input layer of course)'''\n",
        "    \n",
        "        return activations\n",
        "    \n",
        "    def backward_pass(self, targets, layer_activations):\n",
        "        '''Executes the backpropogation algorithm.\n",
        "        \"targets\" is the ground truth/labels\n",
        "        \"layer_activations\" are the return value of the forward pass step\n",
        "        Returns \"deltas\", which is a list containing weight update values for all layers (excluding the input layer of course)'''\n",
        "        \n",
        "        return deltas\n",
        "\n",
        "    def weight_update(self, deltas, layer_inputs, lr):\n",
        "        '''Executes the gradient descent algorithm.\n",
        "        \"deltas\" is return value of the backward pass step\n",
        "        \"layer_inputs\" is a list containing the inputs for all layers (including the input layer)\n",
        "        \"lr\" is the learning rate'''\n",
        "            \n",
        "    def fit(self, Xs, Ys, epochs, lr=1e-3):\n",
        "        '''Trains the model on the given dataset for \"epoch\" number of itterations with step size=\"lr\". \n",
        "        Returns list containing loss for each epoch.'''\n",
        "        history = []\n",
        "        print(Xs.shape)\n",
        "        print(Ys.shape)\n",
        "        for epoch in tqdm_notebook(range(epochs)):\n",
        "            num_samples = Xs.shape[0]\n",
        "            for i in range(num_samples):\n",
        "                sample_input = Xs[i,:].reshape((1,self.input_shape))\n",
        "                sample_target = Ys[i,:].reshape((1,self.output_shape))\n",
        "                \n",
        "                activations =  None # Call forward_pass function  \n",
        "                deltas =  None # Call backward_pass function  \n",
        "\n",
        "                layer_inputs = [sample_input] + activations[:-1]\n",
        "                 None # Call weight_update function  \n",
        "            preds =  None # Call predict function  \n",
        "            if self.mode == 'regression':\n",
        "                current_loss = self.mean_squared_error(preds, Ys)\n",
        "            elif self.mode == 'classification':\n",
        "                current_loss = self.cross_entropy_loss(preds, Ys)\n",
        "            history.append(current_loss)\n",
        "        return history\n",
        "    \n",
        "    def predict(self, Xs):\n",
        "        '''Returns the model predictions (output of the last layer) for the given \"Xs\".'''\n",
        "        predictions = []\n",
        "        num_samples = Xs.shape[0]\n",
        "        for i in range(num_samples):\n",
        "            sample = Xs[i,:].reshape((1,self.input_shape))\n",
        "            sample_prediction = self.forward_pass(sample)[-1]\n",
        "            predictions.append(sample_prediction.reshape((self.output_shape,)))\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def evaluate(self, Xs, Ys):\n",
        "        '''Returns appropriate metrics for the task, calculated on the dataset passed to this method.'''\n",
        "        pred = self.predict(Xs)\n",
        "        if self.mode == 'regression':\n",
        "            return self.mean_squared_error(pred, Ys)\n",
        "        elif self.mode == 'classification':\n",
        "            return self.cross_entropy_loss(pred, Ys), self.accuracy(pred.argmax(axis=1), Ys.argmax(axis=1))\n",
        "    \n",
        "    def plot_model(self, filename):\n",
        "        '''Provide the \"filename\" as a string including file extension. Creates an image showing the model as a graph.'''\n",
        "        graph = pydot.Dot(graph_type='digraph')\n",
        "        graph.set_rankdir('LR')\n",
        "        graph.set_node_defaults(shape='circle', fontsize=0)\n",
        "        for i in range(self.num_layers-1):\n",
        "            for n1 in range(self.nodes_per_layer[i]):\n",
        "                for n2 in range(self.nodes_per_layer[i+1]):\n",
        "                    edge = pydot.Edge(f'l{i}n{n1}', f'l{i+1}n{n2}')\n",
        "                    graph.add_edge(edge)\n",
        "        graph.write_png(filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaYKKAhAaO_z"
      },
      "source": [
        "nn = NeuralNetwork([1,10,1], 'regression')\n",
        "nn.plot_model('graph.png')\n",
        "Image('graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAPN7qABaSal"
      },
      "source": [
        "reg = LinearRegression()\n",
        "reg = reg.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "\n",
        "d = np.arange(-1.5, 2.5, 0.1).reshape((40,1))\n",
        "preds = reg.predict(d)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Linear Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYQdWYulaaCc"
      },
      "source": [
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "\n",
        "nn = NeuralNetwork([1,10,1], 'regression')\n",
        "history = nn.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)), epochs=400, lr=1e-4)\n",
        "preds = nn.predict(d)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='MSE', title='Training Plot {}'.format(rollnumber));\n",
        "# end time\n",
        "end = time.time()\n",
        "print(\"Runtime of the algorithm is \",round((end - start),3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z594nRfAabti"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Neural Network Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "3_auIRSE1X3P"
      },
      "source": [
        "## Task 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "IP7C4gt-1X3Q"
      },
      "source": [
        "Again, if it helps copy only your code from Task3 as a starting point in the next cell. To cap off this assignment you will fully vectorize your implementation. This means changing the primary functions again. There will be a handout on LMS to explain this further.\n",
        "\n",
        "After you do this, the runtime of the `fit` function will just be $O(e)$ (again, assuming all functions called in the loop take constant time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:30:16.547173Z",
          "start_time": "2019-01-27T01:30:16.441918Z"
        },
        "hidden": true,
        "id": "VO5Qq8i21X3Q"
      },
      "source": [
        "class NeuralNetwork():\n",
        "    @staticmethod\n",
        "    def mean_squared_error(y_pred, y_true):\n",
        "        # implement mean_squared_error function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def cross_entropy_loss(y_pred, y_true):\n",
        "        # implement cross_entropy_loss function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def accuracy(y_pred, y_true):\n",
        "        # implement accuracy function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def softmax(x):\n",
        "        # implement softmax function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    @staticmethod\n",
        "    def sigmoid(x):\n",
        "        # implement sigmoid function\n",
        "        #TO DO\n",
        "\n",
        "        return None\n",
        "    \n",
        "    \n",
        "    def __init__(self, nodes_per_layer, mode):\n",
        "        '''Creates a Feed-Forward Neural Network.\n",
        "        \"nodes_per_layer\" is a list containing number of nodes in each layer (including input layer)\n",
        "        \"mode\" can be one of 'regression' or 'classification' and controls the output activation as well as training metric'''\n",
        "        if len(nodes_per_layer) < 2:\n",
        "            raise ValueError('Network must have atleast 2 layers (input and output).')\n",
        "        if not (np.array(nodes_per_layer) > 0).all():\n",
        "            raise ValueError('Number of nodes in all layers must be positive.')\n",
        "        if mode not in ['classification','regression']:\n",
        "            raise ValueError('Only \"classification\" and \"regression\" modes are supported.')\n",
        "        \n",
        "        self.num_layers = None # includes input layer\n",
        "        self.nodes_per_layer = None\n",
        "        self.input_shape = None\n",
        "        self.output_shape = None\n",
        "        self.mode = None\n",
        "        \n",
        "        self.__init_weights(nodes_per_layer)\n",
        "    \n",
        "    def __init_weights(self, nodes_per_layer):\n",
        "        '''Initializes all weights based on standard normal distribution and all biases to 0.'''\n",
        "        self.weights_ = []\n",
        "        self.biases_ = []\n",
        "        for i,_ in enumerate(nodes_per_layer):\n",
        "            if i == 0:\n",
        "                # skip input layer, it does not have weights/bias\n",
        "                continue\n",
        "            \n",
        "            weight_matrix = np.random.normal(size=(None, None))\n",
        "            self.weights_.append(None)\n",
        "            bias_vector = np.zeros(shape=(None,))\n",
        "            self.biases_.append(None)\n",
        "    \n",
        "\n",
        "    def forward_pass(self, input_data):\n",
        "        '''Executes the feed forward algorithm.\n",
        "        \"input_data\" is the input to the network in row-major form\n",
        "        Returns \"activations\", which is a list of all layer outputs (excluding input layer of course)'''\n",
        "\n",
        "        return activations\n",
        "    \n",
        "    def backward_pass(self, targets, layer_activations):\n",
        "        '''Executes the backpropogation algorithm.\n",
        "        \"targets\" is the ground truth/labels\n",
        "        \"layer_activations\" are the return value of the forward pass step\n",
        "        Returns \"deltas\", which is a list containing weight update values for all layers (excluding the input layer of course)'''\n",
        "\n",
        "\n",
        "        return deltas\n",
        "\n",
        "    def weight_update(self, deltas, layer_inputs, lr):\n",
        "        '''Executes the gradient descent algorithm.\n",
        "        \"deltas\" is return value of the backward pass step\n",
        "        \"layer_inputs\" is a list containing the inputs for all layers (including the input layer)\n",
        "        \"lr\" is the learning rate'''\n",
        "\n",
        "\n",
        "    \n",
        "    def fit(self, Xs, Ys, epochs, lr=1e-3):\n",
        "        '''Trains the model on the given dataset for \"epoch\" number of itterations with step size=\"lr\". \n",
        "        Returns list containing loss for each epoch.'''\n",
        "        history = []\n",
        "        print(Xs.shape)\n",
        "        print(Ys.shape)\n",
        "        for epoch in tqdm_notebook(range(epochs)):\n",
        "            num_samples = Xs.shape[0]\n",
        "            for i in range(num_samples):\n",
        "                sample_input = Xs[i,:].reshape((1,self.input_shape))\n",
        "                sample_target = Ys[i,:].reshape((1,self.output_shape))\n",
        "                \n",
        "                activations = None # Call forward_pass function\n",
        "                deltas = None # Call backward_pass function \n",
        "\n",
        "                layer_inputs = [sample_input] + activations[:-1]\n",
        "                None # Call weight_update function\n",
        "            preds = None # Call predict function self.(Xs)\n",
        "            if self.mode == 'regression':\n",
        "                current_loss = self.mean_squared_error(preds, Ys)\n",
        "            elif self.mode == 'classification':\n",
        "                current_loss = self.cross_entropy_loss(preds, Ys)\n",
        "            if  (epoch==epochs-1) and (self.mode == 'classification') and (self.confusion_matrix==True):\n",
        "                  confusion_mat=confusion_matrix(Ys.argmax(axis=1), preds.argmax(axis=1))  \n",
        "                  plot_confusion_matrix(confusion_mat)\n",
        "                  report = classification_report(Ys, np_utils.to_categorical(preds.argmax(axis=1)), target_names=class_labels)\n",
        "                  print(report)\n",
        "            history.append(current_loss)\n",
        "        return history\n",
        "    \n",
        "    def predict(self, Xs):\n",
        "        '''Returns the model predictions (output of the last layer) for the given \"Xs\".'''\n",
        "        predictions = []\n",
        "        num_samples = Xs.shape[0]\n",
        "        for i in range(num_samples):\n",
        "            sample = Xs[i,:].reshape((1,self.input_shape))\n",
        "            sample_prediction = self.forward_pass(sample)[-1]\n",
        "            predictions.append(sample_prediction.reshape((self.output_shape,)))\n",
        "        return np.array(predictions)\n",
        "    \n",
        "    def evaluate(self, Xs, Ys):\n",
        "        '''Returns appropriate metrics for the task, calculated on the dataset passed to this method.'''\n",
        "        pred = self.predict(Xs)\n",
        "        if self.mode == 'regression':\n",
        "            return self.mean_squared_error(pred, Ys)\n",
        "        elif self.mode == 'classification':\n",
        "            return self.cross_entropy_loss(pred, Ys), self.accuracy(pred.argmax(axis=1), Ys.argmax(axis=1))\n",
        "    \n",
        "    def plot_model(self, filename):\n",
        "        '''Provide the \"filename\" as a string including file extension. Creates an image showing the model as a graph.'''\n",
        "        graph = pydot.Dot(graph_type='digraph')\n",
        "        graph.set_rankdir('LR')\n",
        "        graph.set_node_defaults(shape='circle', fontsize=0)\n",
        "        for i in range(self.num_layers-1):\n",
        "            for n1 in range(self.nodes_per_layer[i]):\n",
        "                for n2 in range(self.nodes_per_layer[i+1]):\n",
        "                    edge = pydot.Edge(f'l{i}n{n1}', f'l{i+1}n{n2}')\n",
        "                    graph.add_edge(edge)\n",
        "        graph.write_png(filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzuTlqp_fEVa"
      },
      "source": [
        "### Classification for Task5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_yCf5Yjc7Xs"
      },
      "source": [
        "You will repeat the classfication task on Fashion Mnist dataset. You can change the hidden layers and their sizes to acheive the optimal results. We have passed the confusion_matrix=True for this classification task only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uuby_MMaf4c"
      },
      "source": [
        "# starting time\n",
        "start = time.time()\n",
        "# Define the input size and output size of  Fashion MNIST dataset\n",
        "\n",
        "# You can change the number of hidden layers and their sizes  to get the optimal results\n",
        "\n",
        "nn = NeuralNetwork(nodes_per_layer=[None,None,None],mode='classification',confusion_matrix=True)\n",
        "# You can tweak the learning rate and epochs to get the optimal results\n",
        "history = nn.fit(X_train, y_train, epochs=10, lr=0.01)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='Cross-entropy', title='Training Plot {}'.format(rollnumber));\n",
        "# end time\n",
        "end = time.time()\n",
        "print(\"Runtime of the algorithm is \",round((end - start),3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6ejc_fZfAJt"
      },
      "source": [
        "### Regression for Task5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hidden": true,
        "id": "W3VPzZYc1X3Q"
      },
      "source": [
        "reg = LinearRegression()\n",
        "reg = reg.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "d = np.arange(-1.5, 2.5, 0.1).reshape((40,1))\n",
        "preds = reg.predict(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfMJiELGahgb"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Linear Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKgz6LMMajMb"
      },
      "source": [
        "\n",
        "# starting time\n",
        "start = time.time()\n",
        "\n",
        "nn = NeuralNetwork([1,10,20,10,1], 'regression')\n",
        "history = nn.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)), epochs=2000, lr=1e-4)\n",
        "preds = nn.predict(d)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='MSE', title='Training Plot {}'.format(rollnumber));\n",
        "# end time\n",
        "end = time.time()\n",
        "print(\"Runtime of the algorithm is \",round((end - start),3),\" seconds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Dmuhw_akdw"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Neural Network Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBvu79d61X3R"
      },
      "source": [
        "## Dummy Regression Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:33:04.290893Z",
          "start_time": "2019-01-27T01:33:03.930796Z"
        },
        "id": "R5Yx6qYw1X3R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "92c033e3-dc51-42be-d31a-7086a89588e3"
      },
      "source": [
        "a = np.random.uniform(low=0.0, high=0.5, size=(150,))\n",
        "b = np.random.uniform(low=0.0, high=0.5, size=(150,))\n",
        "dataset = pd.DataFrame({\n",
        "    'var1':   a,\n",
        "    'var2':   b,\n",
        "    'output': a+b,\n",
        "})\n",
        "print(dataset.shape)\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.230785</td>\n",
              "      <td>0.447153</td>\n",
              "      <td>0.677938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.073288</td>\n",
              "      <td>0.334457</td>\n",
              "      <td>0.407745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.135651</td>\n",
              "      <td>0.347177</td>\n",
              "      <td>0.482828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.225609</td>\n",
              "      <td>0.085172</td>\n",
              "      <td>0.310781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.178383</td>\n",
              "      <td>0.469573</td>\n",
              "      <td>0.647956</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       var1      var2    output\n",
              "0  0.230785  0.447153  0.677938\n",
              "1  0.073288  0.334457  0.407745\n",
              "2  0.135651  0.347177  0.482828\n",
              "3  0.225609  0.085172  0.310781\n",
              "4  0.178383  0.469573  0.647956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uap7F2RwamJ0"
      },
      "source": [
        "nn = NeuralNetwork([2,3,5,1], 'regression')\n",
        "nn.plot_model('graph.png')\n",
        "Image('graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIE9otHZanbG"
      },
      "source": [
        "history = nn.fit(dataset[['var1','var2']].values, dataset[['output']].values, epochs=2000, lr=0.001)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='MSE', title='Training Plot {}'.format(rollnumber));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzSetAzhaoru"
      },
      "source": [
        "test_data = np.array([[0.4,0.1],\n",
        "                      [0.2,0.3]])\n",
        "nn.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtcL--GE1X3S"
      },
      "source": [
        "## Dummy Classification Task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:33:56.370640Z",
          "start_time": "2019-01-27T01:33:56.320595Z"
        },
        "id": "O-i7Y1Ud1X3T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "91a727a5-9079-48ef-f7c6-58879a9877e3"
      },
      "source": [
        "# XOR logic operator\n",
        "dataset = pd.DataFrame({\n",
        "    'var1':   [0, 0, 1, 1],\n",
        "    'var2':   [0, 1, 0, 1],\n",
        "    'output': [0, 1, 1, 0],\n",
        "})\n",
        "dataset = pd.get_dummies(dataset, columns=['output'])\n",
        "dataset['output'] = pd.Series([0, 1, 1, 0])\n",
        "print(dataset.shape)\n",
        "dataset.head()\n",
        "# The columns 'output_0' and 'output_1' are one-hot encoded representation of the categorical column 'output'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>output_0</th>\n",
              "      <th>output_1</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   var1  var2  output_0  output_1  output\n",
              "0     0     0         1         0       0\n",
              "1     0     1         0         1       1\n",
              "2     1     0         0         1       1\n",
              "3     1     1         1         0       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OgJQGb0arxB"
      },
      "source": [
        "nn = NeuralNetwork([2,5,2], 'classification')\n",
        "nn.plot_model('graph.png')\n",
        "Image('graph.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6KnM5JoatU_"
      },
      "source": [
        "history = nn.fit(dataset[['var1','var2']].values, dataset[['output_0','output_1']].values, epochs=3000, lr=0.01)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='Cross-entropy', title='Training Plot {}'.format(rollnumber));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMeUOr0wau_T"
      },
      "source": [
        "nn.predict(dataset[['var1','var2']].values).argmax(axis=1) == dataset[['output_0','output_1']].values.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibnra4Hz1X3U"
      },
      "source": [
        "## Regression Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZTtDwbW1X3U"
      },
      "source": [
        "Code for Demos adapted from tutorial 1, refer to it if you need a refresher (available on LMS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:34:17.130755Z",
          "start_time": "2019-01-27T01:34:16.900688Z"
        },
        "id": "Qul7Yh7C1X3U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "a7d09e81-58a7-4bea-c26e-d2a4a14ecc27"
      },
      "source": [
        "data_x, _ = make_moons(200, noise=0.18)\n",
        "plt.scatter(data_x[:,0], data_x[:,1]);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:34:20.010456Z",
          "start_time": "2019-01-27T01:34:19.400302Z"
        },
        "id": "zwNfkIqH1X3U"
      },
      "source": [
        "reg = LinearRegression()\n",
        "reg = reg.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "\n",
        "d = np.arange(-1.5, 2.5, 0.1).reshape((40,1))\n",
        "preds = reg.predict(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9w0I9RXaxK8"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Linear Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjByvs0zayqO"
      },
      "source": [
        "nn = NeuralNetwork([1,10,20,10,1], 'regression')\n",
        "history = nn.fit(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)), epochs=20000, lr=1e-4)\n",
        "preds = nn.predict(d)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='MSE', title='Training Plot {}'.format(rollnumber));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ke6w9eazu9"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.scatter(data_x[:,0].reshape((200,1)), data_x[:,1].reshape((200,1)));\n",
        "ax.plot(d.flatten(), preds.flatten(), c='tab:red', label='Prediction');\n",
        "ax.set(xlabel='Input Feature', ylabel='Target Variable', title='Neural Network Regression {}'.format(rollnumber));\n",
        "ax.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "qQ9VCox-1X3V"
      },
      "source": [
        "## Classification Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:35:05.630191Z",
          "start_time": "2019-01-27T01:35:05.600080Z"
        },
        "hidden": true,
        "id": "oF3wk8I-1X3V"
      },
      "source": [
        "# Helper function to plot a decision boundary.\n",
        "# If you don't fully understand this function don't worry\n",
        "def plot_decision_boundary(pred_func, x_min, x_max, y_min, y_max, cmap, ax):\n",
        "    h = 0.01\n",
        "    # Generate a grid of points with distance h between them\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "    # Predict the function value for the whole gid\n",
        "    Z = pred_func(np.c_[xx.flatten(), yy.flatten()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "    # Plot the contour\n",
        "    ax.contourf(xx, yy, Z, cmap=cmap, alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0ij_Xhya1Dp"
      },
      "source": [
        "data_x, data_y = make_moons(200, noise=0.20)\n",
        "plt.scatter(data_x[:,0], data_x[:,1], c=data_y, cmap=plt.cm.Spectral);\n",
        "plt.gca().set(xlabel='Feature 1', ylabel='Feature 2');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-27T01:35:09.680260Z",
          "start_time": "2019-01-27T01:35:09.399995Z"
        },
        "hidden": true,
        "id": "2XR9ALbf1X3W"
      },
      "source": [
        "clf = LogisticRegression(solver='lbfgs')\n",
        "clf = clf.fit(data_x, data_y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-tNt9g3a2T6"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "x_min, x_max = data_x[:, 0].min() - .5, data_x[:, 0].max() + .5\n",
        "y_min, y_max = data_x[:, 1].min() - .5, data_x[:, 1].max() + .5\n",
        "plot_decision_boundary(lambda x: clf.predict(x), \n",
        "                       x_min, x_max, y_min, y_max, \n",
        "                       plt.cm.Spectral, ax)\n",
        "ax.scatter(data_x[:,0], data_x[:,1], c=data_y, cmap=plt.cm.Spectral);\n",
        "ax.set(xlabel='Feature 1', ylabel='Feature 2', title='Logistic Regression Classifier {}'.format(rollnumber));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBh65XGea5Kb"
      },
      "source": [
        "nn = NeuralNetwork([2,10,10,2], 'classification')\n",
        "history = nn.fit(data_x, pd.get_dummies(data_y).values, epochs=2000, lr=1e-3)\n",
        "plt.plot(history);\n",
        "plt.gca().set(xlabel='Epoch', ylabel='Cross-entropy', title='Training Plot {}'.format(rollnumber));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt71VoK2a6Jp"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "x_min, x_max = data_x[:, 0].min() - .5, data_x[:, 0].max() + .5\n",
        "y_min, y_max = data_x[:, 1].min() - .5, data_x[:, 1].max() + .5\n",
        "plot_decision_boundary(lambda x: nn.predict(x).argmax(axis=1), \n",
        "                       x_min, x_max, y_min, y_max, \n",
        "                       plt.cm.Spectral, ax)\n",
        "ax.scatter(data_x[:,0], data_x[:,1], c=data_y, cmap=plt.cm.Spectral);\n",
        "ax.set(xlabel='Feature 1', ylabel='Feature 2', title='Neural Network Classifier {}'.format(rollnumber));"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}